{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ecdfe2-d0a4-4458-9498-11370a5f155d",
   "metadata": {},
   "source": [
    "# EDA of Chatbot Arena Dataset -- Starter Notebook\n",
    "\n",
    "This notebook aims to help you explore the Chatbot Arena dataset, where two chatbots answer human questions, and users vote on the best response. Through this EDA, we will:\n",
    "- Understand the dataset structure and contents.\n",
    "- Explore the distribution of questions, responses, and chatbots.\n",
    "- Identify patterns in the data to guide future modeling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e682f63a-4115-4e2c-90ba-5c1f0eef35c3",
   "metadata": {},
   "source": [
    "## 1. Understanding the Dataset\n",
    "The source dataset comes from https://huggingface.co/datasets/lmsys/chatbot_arena_conversations. The author describes the dataset as follows:\n",
    "\n",
    "> This dataset contains 33K cleaned conversations with pairwise human preferences. It is collected from 13K unique IP addresses on the Chatbot Arena from April to June 2023. Each sample includes a question ID, two model names, their full conversation text in OpenAI API JSON format, the user vote, the anonymized user ID, the detected language tag, the OpenAI moderation API tag, the additional toxic tag, and the timestamp.\n",
    "\n",
    "[Chatbot Arena](https://chat.lmsys.org/) is a platform where users can ask questions and two chatbots will provide answers. The user then votes on which chatbot provided the best answer. The dataset contains the questions, the answers, and the user votes.\n",
    "\n",
    "### Main Dataset\n",
    "\n",
    "- **Conversation Data**\n",
    "You can find the processed dataset in `./chatbot-arena-conversations.jsonl.gz`. The dataset is in JSON line format and compressed using gzip. It has gone through the following preprocessing steps to make analysis easier:\n",
    "\n",
    "    - Removed non-English conversations.\n",
    "    - Removed conversations with more than one round.\n",
    "    - Removed conversations classified as toxic or harmful.\n",
    "\n",
    "The dataset you will be working with contains `25282` rows (out of `33000` total rows) and `7` columns. The columns are:\n",
    "\n",
    "- `question_id`: A unique identifier for the question.\n",
    "- `model_a`: The name of the first chatbot model.\n",
    "- `model_b`: The name of the second chatbot model.\n",
    "- `winner`: The name of the chatbot model that won the user vote.\n",
    "- `judge`: The anonymized user ID that voted.\n",
    "- `conversation_a`: The conversation between the user and `model_a`.\n",
    "- `conversation_b`: The conversation between the user and `model_b`.\n",
    "\n",
    "An example of the data is as follows:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"question_id\": \"c0fc42c6f5f14f2aa5a89f71f8553730\",\n",
    "  \"model_a\": \"vicuna-13b\",\n",
    "  \"model_b\": \"koala-13b\",\n",
    "  \"winner\": \"model_a\",\n",
    "  \"judge\": \"arena_user_973\",\n",
    "  \"conversation_a\": [\n",
    "    {\n",
    "      \"content\": \"Count from 1 to 10 with step = 3\",\n",
    "      \"role\": \"user\"\n",
    "    },\n",
    "    {\n",
    "      \"content\": \"1, 4, 7, 10\\n\\nCounting with a step of 3 means that you will increase the number by 3 each time. So, the first number is 1, the next is 4 (1 + 3), the next is 7 (4 + 3), and so on.\",\n",
    "      \"role\": \"assistant\"\n",
    "    }\n",
    "  ],\n",
    "  \"conversation_b\": [\n",
    "    {\n",
    "      \"content\": \"Count from 1 to 10 with step = 3\",\n",
    "      \"role\": \"user\"\n",
    "    },\n",
    "    {\n",
    "      \"content\": \"1, 4, 7, 10\",\n",
    "      \"role\": \"assistant\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### Auxiliary Datasets\n",
    "\n",
    "There are four auxiliary datasets that you can use to help with your analysis:\n",
    "\n",
    "- **Embedding Data**\n",
    "    - `./chatbot-arena-prompts-embeddings.npy` contains the 256-dimensional text embeddings for each of the human questions. The embeddings are generated using OpenAI’s text-embedding model. We will explain what embeddings are and how you can use them later.\n",
    "    - `./chatbot-arena-model_a_response-embeddings.npy` contains the 256-dimensional text embeddings for each of the model a responses (second half of conversation a). The embeddings are generated using OpenAI’s text-embedding model. \n",
    "     - `./chatbot-arena-model_b_response-embeddings.npy` contains the 256-dimensional text embeddings for each of of the model b responses (second half of conversation b). The embeddings are generated using OpenAI’s text-embedding model.\n",
    "\n",
    "- **Topic Modeling and Hardness Score Data**\n",
    "- `./chatbot-arena-gpt3-scores.jsonl.gz` ([example row](https://gist.github.com/simon-mo/25c5d532bccc7f28b404cffdfe719e6e#file-example-aux-row-json))\n",
    " contains labels for the dataset, which you can use for later modeling tasks. It has the following fields:\n",
    "  - **question_id**: The unique identifier for the question, as seen in `./chatbot-arena-conversations.jsonl.gz`.\n",
    "  - **prompt**: The extracted human question. This is equivalent to the first message in `conversation_a` and `conversation_b` in `./chatbot-arena-conversations.jsonl.gz`.\n",
    "  - **openai_scores_raw_choices_nested**: The response from OpenAI GPT 3.5 model. It contains:\n",
    "    - The evaluated topic model\n",
    "    - The reason for a hardness score (from 1 to 10)\n",
    "    - The score value\n",
    "\n",
    "  For each prompt, we have 3 responses from GPT 3.5 because it is a probabilistic model. In the real world, multiple annotators may provide different labels for ground truth data. We extracted the following fields into columns:\n",
    "\n",
    "  - **topic_modeling_1, topic_modeling_2, topic_modeling_3**: Topic modeling for the first, second, and third response. Each topic contains two words.\n",
    "  - **score_reason_1, score_reason_2, score_reason_3**: The reasons for the hardness score for the first, second, and third response.\n",
    "  - **score_value_1, score_value_2, score_value_3**: The hardness score for the first, second, and third response.\n",
    " \n",
    "```json\n",
    "{\n",
    "  \"question_id\": \"58210e39b3fd4441a2bd4a518bb44c2d\",\n",
    "  \"prompt\": \"What is the difference between OpenCL and CUDA?\",\n",
    "  \"openai_scores_raw_choices_nested\": [\n",
    "    {\n",
    "      \"finish_reason\": \"stop\",\n",
    "      \"index\": 0,\n",
    "      \"logprobs\": null,\n",
    "      \"message\": {\n",
    "        \"content\": \"{\\n    \\\"topic_modeling\\\": \\\"Technical Comparison\\\",\\n    \\\"score_reason\\\": \\\"This prompt requires the AI to accurately compare and contrast two distinct technologies, OpenCL and CUDA. It assesses the AI's factual accuracy and knowledge of these technologies, as well as its ability to articulate the differences between them.\\\",\\n    \\\"score_value\\\": 9\\n}\",\n",
    "        \"role\": \"assistant\",\n",
    "        \"function_call\": null,\n",
    "        \"tool_calls\": null\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"finish_reason\": \"stop\",\n",
    "      \"index\": 1,\n",
    "      \"logprobs\": null,\n",
    "      \"message\": {\n",
    "        \"content\": \"{\\n    \\\"topic_modeling\\\": \\\"Software Comparison\\\",\\n    \\\"score_reason\\\": \\\"This prompt assesses the AI's factual accuracy in distinguishing between two similar but distinct software frameworks.\\\",\\n    \\\"score_value\\\": 8\\n}\",\n",
    "        \"role\": \"assistant\",\n",
    "        \"function_call\": null,\n",
    "        \"tool_calls\": null\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"finish_reason\": \"stop\",\n",
    "      \"index\": 2,\n",
    "      \"logprobs\": null,\n",
    "      \"message\": {\n",
    "        \"content\": \"{\\n    \\\"topic_modeling\\\": \\\"Comparison, Technology\\\",\\n    \\\"score_reason\\\": \\\"This prompt requires the AI to demonstrate knowledge of two different technologies, compare their features, and explain their distinctions. This task assesses the AI's factual accuracy and proficiency in understanding complex technological concepts.\\\",\\n    \\\"score_value\\\": 9\\n}\",\n",
    "        \"role\": \"assistant\",\n",
    "        \"function_call\": null,\n",
    "        \"tool_calls\": null\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"topic_modeling_1\": \"Technical Comparison\",\n",
    "  \"score_reason_1\": \"This prompt requires the AI to accurately compare and contrast two distinct technologies, OpenCL and CUDA. It assesses the AI's factual accuracy and knowledge of these technologies, as well as its ability to articulate the differences between them.\",\n",
    "  \"score_value_1\": 9,\n",
    "  \"topic_modeling_2\": \"Software Comparison\",\n",
    "  \"score_reason_2\": \"This prompt assesses the AI's factual accuracy in distinguishing between two similar but distinct software frameworks.\",\n",
    "  \"score_value_2\": 8,\n",
    "  \"topic_modeling_3\": \"Comparison, Technology\",\n",
    "  \"score_reason_3\": \"This prompt requires the AI to demonstrate knowledge of two different technologies, compare their features, and explain their distinctions. This task assesses the AI's factual accuracy and proficiency in understanding complex technological concepts.\",\n",
    "  \"score_value_3\": 9\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d5d37-3635-4412-bd0e-9f28874116ef",
   "metadata": {},
   "source": [
    "## 2. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6594a806-ebcc-4947-bf4b-938cdbba27dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "356f370f-b361-453d-8aa3-85e1dc3555d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all datasets\n",
    "df = pd.read_json(\n",
    "    \"../data/training-set/chatbot-arena-conversations.jsonl.gz\",\n",
    "    lines=True,\n",
    "    compression=\"gzip\"\n",
    ")\n",
    "df.head(5)\n",
    "prompt_embeddings = np.load(\n",
    "    \"../data/training-set/chatbot-arena-prompts-embeddings.npy\"\n",
    ")\n",
    "\n",
    "response_a_embeddings = np.load(\n",
    "    \"../data/training-set/chatbot-arena-model_a_response-embeddings.npy\"\n",
    ")\n",
    "\n",
    "response_b_embeddings = np.load(\n",
    "    \"../data/training-set/chatbot-arena-model_b_response-embeddings.npy\"\n",
    ")\n",
    "\n",
    "topic_and_hardness = pd.read_csv(\"../data/training-set/topic_hardness_embedding_cluster_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c635f536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chatglm-6b' 'oasst-pythia-12b' 'koala-13b' 'vicuna-13b'\n",
      " 'stablelm-tuned-alpha-7b' 'alpaca-13b' 'llama-13b' 'dolly-v2-12b'\n",
      " 'fastchat-t5-3b' 'gpt-3.5-turbo' 'gpt-4' 'claude-v1' 'RWKV-4-Raven-14B'\n",
      " 'mpt-7b-chat' 'palm-2' 'claude-instant-v1' 'vicuna-7b' 'wizardlm-13b'\n",
      " 'gpt4all-13b-snoozy' 'guanaco-33b']\n"
     ]
    }
   ],
   "source": [
    "models = df[\"model_a\"].unique()\n",
    "print (models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79dea3a-89c9-458c-a36e-e322c4c5fe20",
   "metadata": {},
   "source": [
    "## 3. Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8786dd59-23e1-44b6-82ce-b5aaf4efbba4",
   "metadata": {},
   "source": [
    "### Converstation Data\n",
    "\n",
    "Let's investigate the conversation data first (`chatbot-arena-conversations.jsonl.gz`). It is in JSON line format, compressed with `gzip`. You can load the data with `pd.read_json`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9ed851-e2a8-4b2a-94fa-2e03195759a6",
   "metadata": {},
   "source": [
    "Before diving into any analysis, it's important to understand the structure of the dataset. In this section, we'll check the basic details of the data, such as the number of rows, column names, data types, and any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bfcd55c-8332-4622-9336-129aa22215f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25282 entries, 0 to 25281\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   question_id     25282 non-null  object\n",
      " 1   model_a         25282 non-null  object\n",
      " 2   model_b         25282 non-null  object\n",
      " 3   winner          25282 non-null  object\n",
      " 4   judge           25282 non-null  object\n",
      " 5   conversation_a  25282 non-null  object\n",
      " 6   conversation_b  25282 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ff52110-9e14-43a3-aa80-716240937942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_id       0\n",
       "model_a           0\n",
       "model_b           0\n",
       "winner            0\n",
       "judge             0\n",
       "conversation_a    0\n",
       "conversation_b    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142fe89b-5400-4c99-8fe8-c007f7dd52ca",
   "metadata": {},
   "source": [
    "As an example to guide you through the exploratory process, let’s investigate the length distribution of the prompt. This helps answer questions like (this is related to the ``Distribution of the prompt and response length'' requirement of the EDA assingment).\n",
    ": \n",
    "\n",
    "- Do the arena users ask long or short questions?\n",
    "- What is the average length of prompts that users give to the chatbots?\n",
    "\n",
    "By analyzing the length of the prompts, you can start forming hypotheses about how the length might affect model performance or user votes. This example will guide you in asking similar questions about other aspects of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1d8d23d-158d-41f7-8942-f0f301740340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    What is the difference between OpenCL and CUDA?\n",
       "Name: prompt, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"prompt\"] = df[\"conversation_a\"].str[0].str[\"content\"]\n",
    "df[\"prompt\"].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fd2e311-9ef9-4b3c-9cee-4a5b73c00743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25282.00000\n",
       "mean       196.74646\n",
       "std        369.05595\n",
       "min         16.00000\n",
       "25%         42.00000\n",
       "50%         72.00000\n",
       "75%        156.00000\n",
       "max       2560.00000\n",
       "Name: prompt_length, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"prompt_length\"] = df[\"prompt\"].str.len()\n",
    "df[\"prompt_length\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0029eb-d56a-4365-b2a8-6ad7f25ac241",
   "metadata": {},
   "source": [
    "Looks like the mean length of the prompt is about **200 characters, while the median is 72 characters**. This suggests that the distribution is **right-skewed!** Let's visualize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0656e01-e3db-4673-bdd1-c47446ca96f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='prompt_length', ylabel='Count'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of the length of the prompt\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df[\"prompt_length\"], kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f738b9-3b65-4eee-b550-73aec71d58c3",
   "metadata": {},
   "source": [
    "Now, can you apply the same thought process to visualize the distribution of the response length? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3e175e-a2be-4529-8c86-00c7a8b628f2",
   "metadata": {},
   "source": [
    "Applying the same logic you used to make the `prompt` column, you should also make the columns `model_a_response` and `model_b_response` by extracting the **second half** of the content from `conversation_a` and `conversation_b` respectively in order to look into specific content of the model responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626074ea-6660-4cfd-a4fa-17d2249d9304",
   "metadata": {},
   "source": [
    "### Embedding Data\n",
    "\n",
    "Text embedding models transform natural language text into numerical vectors. The vectors are generated in such a way that semantically similar text are close to each other in the vector space. In the real world, these embeddings to find similar questions or to cluster the questions.\n",
    "\n",
    "Concretely, the auxiliary dataset,`./chatbot-arena-prompts-embeddings.npy`, `./chatbot-arena-model_a_response-embeddings.npy`, and `./chatbot-arena-model_b_response-embeddings.npy`, contains 256-dimensional text embeddings for each of the human questions, model a responses and model b responses respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a4bbd-4d47-4c45-b035-34425934fc4b",
   "metadata": {},
   "source": [
    "In this section, we will walk you through an example of computing the similarity between prompts using the precomputed embeddings (`./chatbot-arena-prompts-embeddings.npy`). The goal is to find prompts that are most similar to a given prompt based on their embeddings.\n",
    "\n",
    "Before we get started, let's first load and output the `propmt_embeddings` which we have loaded in the second section to see what they look like. Each embedding is a 256-dimensional vector that represents the semantic meaning of a prompt. These vectors allow us to compare prompts based on their content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44759049-09d6-4850-b21d-c194943a9c92",
   "metadata": {},
   "source": [
    "The embeddings are a matrix where each row corresponds to a prompt from the dataset. Each row is a 256-dimensional vector that captures the semantic meaning of the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d67d2105-bbf0-4323-a0bf-603d0ce70f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25282, 256)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa079ce-05af-498f-b87a-d4f3720ae5e5",
   "metadata": {},
   "source": [
    "The embeddings array has a shape of `(25282, 256)`, meaning there are 25,282 embeddings (one for each prompt), and each embedding is a 256-dimensional vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7543f-a340-4ee0-af64-956ad83e2254",
   "metadata": {},
   "source": [
    "Next, we will:\n",
    "1. Take a sample of the embeddings to reduce computation time.\n",
    "2. Compute the dot product between the embeddings to measure similarity.\n",
    "3. Retrieve the most similar prompts to a chosen source prompt.\n",
    "4. Output the top 5 similar prompts.\n",
    "(This is related to the ``(Open-ended) Explore the prompt topics in the dataset (topic modeling).'' requirement of the EDA assignment)\n",
    "\n",
    "Start by taking a sample of the embeddings and calculating the similarity between them using the dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d127aa9f-763e-4086-9ae5-9464ff37f3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try to find the closest prompt to a given prompt\n",
    "embeddings_sample = prompt_embeddings[:1000]\n",
    "\n",
    "# Compute the dot product between the embeddings\n",
    "dot_product = np.dot(embeddings_sample, embeddings_sample.T)\n",
    "dot_product.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac287514-b2d2-4c2c-8250-cbaeec97d73b",
   "metadata": {},
   "source": [
    "Given the above output, the dot product matrix has a shape of (1000, 1000), meaning we have similarity scores between all pairs of prompts in our sample of 1000.\n",
    "\n",
    "Next, let's choose a prompt and find the top 5 most similar prompts based on the computed similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ea1a18d-6b3b-4f28-8ca3-24ea8b1689d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write me a function to lazily compute a Fibonacci sequence in Clojure. '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_prompt_idx = 23\n",
    "source_prompt = df.iloc[source_prompt_idx].prompt\n",
    "source_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a72a91-5a4c-447c-9489-4f7b4fa8844b",
   "metadata": {},
   "source": [
    "The prompt we're using as a reference (index 23) is:\n",
    "\n",
    "`'Write me a function to lazily compute a Fibonacci sequence in Clojure.'`\n",
    "\n",
    "Now let's find the top 5 most similar prompts to this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69c8b1b8-9279-4c4f-87f5-f01f5f154822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Write me a function to lazily compute a Fibonacci sequence in Clojure. ',\n",
       " \"Let's write a function that sums every third number from 1 to 100.\",\n",
       " 'Write an efficient Fibonacci number calculator in Python. ',\n",
       " 'Write a program in Ocaml to compute the square root of a number.',\n",
       " 'What is a pure function?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 5\n",
    "similar_promts_idx = np.argsort(dot_product[source_prompt_idx])[-top_k:][::-1]\n",
    "similar_promts = df.iloc[similar_promts_idx].prompt\n",
    "similar_promts.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0ce403-0390-44b5-9747-1f84f124c681",
   "metadata": {},
   "source": [
    "As you can see, these prompts are closely related to programming tasks, many of them dealing with functions and computations. This shows how embeddings can group semantically similar questions together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17908262-6a3f-4867-8c05-49cf5704954e",
   "metadata": {},
   "source": [
    "You also have the embeddings for responses from models a (`./chatbot-arena-model_a_response-embeddings.npy`) and model b (`./chatbot-arena-model_b_response-embeddings.npy`) respectively to explore. (These are the embeddings from columns `model_a_response` and `model_b_response` which can be created by extracting the second half of columns `conversation_a` and `conversation_b` respectively (as explained in the previous section)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae89944-fffb-4dd4-a33f-5f7286d3d669",
   "metadata": {},
   "source": [
    "Potential follow-up questions you can explore: \n",
    "- Can you identify clusters of similar topics within the dataset?\n",
    "- How do different models perform on similar prompts?\n",
    "- Can you find examples where semantically similar prompts result in different outcomes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39856510-10f6-4060-b837-013fbbeb5544",
   "metadata": {},
   "source": [
    "### Topic Modeling and Hardness Score Data\n",
    "\n",
    "Now, let's explore the second auxiliary dataset `./chatbot-arena-gpt3-scores.jsonl.gz`, which contains valuable information for later modeling tasks. \n",
    "\n",
    "For each prompt, there are 3 responses, as GPT-3.5 is probabilistic. This means we get multiple labels for a single prompt, similar to how real-world datasets can have multiple annotations.\n",
    "\n",
    "Let's start by loading and inspecting the first 5 rows of this dataset to understand its structure.\n",
    "\n",
    "**_Warning_: This data can be messy! This is intentionally not cleaned up for you to resemble real-world data. You are responsible for figuring out the irregularities and cleaning it up. The following cells demonstrate the example of messy data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9022d114-d745-496e-bbcc-0586f5f550b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>openai_scores_raw_choices_nested</th>\n",
       "      <th>topic_modeling_1</th>\n",
       "      <th>score_reason_1</th>\n",
       "      <th>score_value_1</th>\n",
       "      <th>topic_modeling_2</th>\n",
       "      <th>score_reason_2</th>\n",
       "      <th>score_value_2</th>\n",
       "      <th>topic_modeling_3</th>\n",
       "      <th>score_reason_3</th>\n",
       "      <th>score_value_3</th>\n",
       "      <th>prompt_objective</th>\n",
       "      <th>objective_term</th>\n",
       "      <th>prompt_topic</th>\n",
       "      <th>topic_term</th>\n",
       "      <th>Agglo_Cluster</th>\n",
       "      <th>HDBSCAN_Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>What is the difference between OpenCL and CUDA?</td>\n",
       "      <td>[{'finish_reason': 'stop', 'index': 0, 'logpro...</td>\n",
       "      <td>technical comparison</td>\n",
       "      <td>This prompt requires the AI to accurately comp...</td>\n",
       "      <td>9</td>\n",
       "      <td>software comparison</td>\n",
       "      <td>This prompt assesses the AI's factual accuracy...</td>\n",
       "      <td>8</td>\n",
       "      <td>comparison, technology</td>\n",
       "      <td>This prompt requires the AI to demonstrate kno...</td>\n",
       "      <td>9</td>\n",
       "      <td>comparing</td>\n",
       "      <td>comparison</td>\n",
       "      <td>programming</td>\n",
       "      <td>software</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2564acd09e3942fd97657d05282d4389</td>\n",
       "      <td>Why did my parent not invite me to their wedding?</td>\n",
       "      <td>[{'finish_reason': 'stop', 'index': 0, 'logpro...</td>\n",
       "      <td>reasoning, emotion</td>\n",
       "      <td>This prompt requires the AI to understand huma...</td>\n",
       "      <td>9</td>\n",
       "      <td>emotions, relationships</td>\n",
       "      <td>This prompt involves understanding complex hum...</td>\n",
       "      <td>8</td>\n",
       "      <td>reasoning, emotional</td>\n",
       "      <td>This prompt challenges the AI to infer motives...</td>\n",
       "      <td>8</td>\n",
       "      <td>comparing</td>\n",
       "      <td>relation</td>\n",
       "      <td>Social</td>\n",
       "      <td>emotion</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>90bfd142157948aba01931726c888e7f</td>\n",
       "      <td>Fuji vs. Nikon, which is better?</td>\n",
       "      <td>[{'finish_reason': 'stop', 'index': 0, 'logpro...</td>\n",
       "      <td>camera comparison</td>\n",
       "      <td>This prompt does not require problem-solving s...</td>\n",
       "      <td>2</td>\n",
       "      <td>comparative analysis</td>\n",
       "      <td>This prompt assesses the AI's ability to analy...</td>\n",
       "      <td>6</td>\n",
       "      <td>photography comparison</td>\n",
       "      <td>This prompt is subjective and does not provide...</td>\n",
       "      <td>2</td>\n",
       "      <td>comparing</td>\n",
       "      <td>comparison</td>\n",
       "      <td>technology</td>\n",
       "      <td>photography</td>\n",
       "      <td>18</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a7c5accc53e649a3bc6b2e41d962ebc4</td>\n",
       "      <td>How to build an arena for chatbots?</td>\n",
       "      <td>[{'finish_reason': 'stop', 'index': 0, 'logpro...</td>\n",
       "      <td>chatbot arena</td>\n",
       "      <td>This prompt requires problem-solving skills an...</td>\n",
       "      <td>8</td>\n",
       "      <td>chatbot arena</td>\n",
       "      <td>This prompt requires the AI to engage in probl...</td>\n",
       "      <td>8</td>\n",
       "      <td>chatbot arena</td>\n",
       "      <td>This prompt requires problem-solving skills an...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>30</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>adf27e819a3c494cb6e993f0c660e097</td>\n",
       "      <td>When is it today?</td>\n",
       "      <td>[{'finish_reason': 'stop', 'index': 0, 'logpro...</td>\n",
       "      <td>time query</td>\n",
       "      <td>This prompt is very straightforward and does n...</td>\n",
       "      <td>2</td>\n",
       "      <td>date inquiry</td>\n",
       "      <td>This prompt is very straightforward and does n...</td>\n",
       "      <td>2</td>\n",
       "      <td>time-based inquiry</td>\n",
       "      <td>This prompt is too straightforward and simply ...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       question_id  \\\n",
       "0           0  58210e39b3fd4441a2bd4a518bb44c2d   \n",
       "1           1  2564acd09e3942fd97657d05282d4389   \n",
       "2           2  90bfd142157948aba01931726c888e7f   \n",
       "3           3  a7c5accc53e649a3bc6b2e41d962ebc4   \n",
       "4           4  adf27e819a3c494cb6e993f0c660e097   \n",
       "\n",
       "                                              prompt  \\\n",
       "0    What is the difference between OpenCL and CUDA?   \n",
       "1  Why did my parent not invite me to their wedding?   \n",
       "2                   Fuji vs. Nikon, which is better?   \n",
       "3                How to build an arena for chatbots?   \n",
       "4                                  When is it today?   \n",
       "\n",
       "                    openai_scores_raw_choices_nested      topic_modeling_1  \\\n",
       "0  [{'finish_reason': 'stop', 'index': 0, 'logpro...  technical comparison   \n",
       "1  [{'finish_reason': 'stop', 'index': 0, 'logpro...    reasoning, emotion   \n",
       "2  [{'finish_reason': 'stop', 'index': 0, 'logpro...     camera comparison   \n",
       "3  [{'finish_reason': 'stop', 'index': 0, 'logpro...         chatbot arena   \n",
       "4  [{'finish_reason': 'stop', 'index': 0, 'logpro...            time query   \n",
       "\n",
       "                                      score_reason_1 score_value_1  \\\n",
       "0  This prompt requires the AI to accurately comp...             9   \n",
       "1  This prompt requires the AI to understand huma...             9   \n",
       "2  This prompt does not require problem-solving s...             2   \n",
       "3  This prompt requires problem-solving skills an...             8   \n",
       "4  This prompt is very straightforward and does n...             2   \n",
       "\n",
       "          topic_modeling_2                                     score_reason_2  \\\n",
       "0      software comparison  This prompt assesses the AI's factual accuracy...   \n",
       "1  emotions, relationships  This prompt involves understanding complex hum...   \n",
       "2     comparative analysis  This prompt assesses the AI's ability to analy...   \n",
       "3            chatbot arena  This prompt requires the AI to engage in probl...   \n",
       "4             date inquiry  This prompt is very straightforward and does n...   \n",
       "\n",
       "  score_value_2        topic_modeling_3  \\\n",
       "0             8  comparison, technology   \n",
       "1             8    reasoning, emotional   \n",
       "2             6  photography comparison   \n",
       "3             8           chatbot arena   \n",
       "4             2      time-based inquiry   \n",
       "\n",
       "                                      score_reason_3 score_value_3  \\\n",
       "0  This prompt requires the AI to demonstrate kno...             9   \n",
       "1  This prompt challenges the AI to infer motives...             8   \n",
       "2  This prompt is subjective and does not provide...             2   \n",
       "3  This prompt requires problem-solving skills an...             8   \n",
       "4  This prompt is too straightforward and simply ...             2   \n",
       "\n",
       "  prompt_objective objective_term prompt_topic   topic_term  Agglo_Cluster  \\\n",
       "0        comparing     comparison  programming     software              1   \n",
       "1        comparing       relation       Social      emotion              6   \n",
       "2        comparing     comparison   technology  photography             18   \n",
       "3              NaN            NaN           AI      chatbot             30   \n",
       "4              NaN            NaN          NaN          NaN             14   \n",
       "\n",
       "   HDBSCAN_Cluster  \n",
       "0              169  \n",
       "1               -1  \n",
       "2              131  \n",
       "3              190  \n",
       "4               69  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_and_hardness.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c1780b-4252-4ee7-85ac-a8670ce6d13c",
   "metadata": {},
   "source": [
    "**Understand the Structure**\n",
    "How are the topic modeling and hardness scores structured across the dataset?\n",
    "- Look at the columns `topic_modeling_1`, `score_reason_1`, `score_value_1`, etc.\n",
    "- How consistent are the values across the rows? Do they follow a pattern? Are there any irregularities or unexpected values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac487283-c64e-45e0-a215-b3494042a8d8",
   "metadata": {},
   "source": [
    "**Data Cleaning**\n",
    "The following are some of the things (many) you should explore to clean your data:\n",
    "- Are there any missing values?\n",
    "- The data in the `openai_scores_raw_choices_nested` field appears messy. It contains a list of nested dictionaries that might need to be flattened for easier analysis. Consider these points:\n",
    "    - Do you need all the nested data? Perhaps you only need the final hardness scores and topic modeling results for your analysis.\n",
    "    - One way to deal with the nested openai_scores_raw_choices_nested field is to flatten it into more readable columns if you find you need the nested data.\n",
    "- Sometimes, there could be repeated entries in the dataset. Make sure that each question (question_id) and its corresponding responses are unique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388a828-059c-47fc-a63b-5522e1ee0b43",
   "metadata": {},
   "source": [
    "Let’s begin by checking for missing values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d0999b9-1e01-4422-be03-9ccb160872e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                              0\n",
       "question_id                             0\n",
       "prompt                                  0\n",
       "openai_scores_raw_choices_nested        0\n",
       "topic_modeling_1                       29\n",
       "score_reason_1                         26\n",
       "score_value_1                          26\n",
       "topic_modeling_2                       28\n",
       "score_reason_2                         26\n",
       "score_value_2                          26\n",
       "topic_modeling_3                       27\n",
       "score_reason_3                         26\n",
       "score_value_3                          26\n",
       "prompt_objective                     9346\n",
       "objective_term                       9346\n",
       "prompt_topic                        13090\n",
       "topic_term                          13090\n",
       "Agglo_Cluster                           0\n",
       "HDBSCAN_Cluster                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_and_hardness.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa314486-3380-4c66-8bc1-184c92cb237c",
   "metadata": {},
   "source": [
    "What are some strategies for handling missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb936ab-4d91-4913-abab-b6975a86a883",
   "metadata": {},
   "source": [
    "Messy data is not only about missing values, it can also be about inconsistent formatting. Let's check for inconsistencies in the `score_value_1` column of the dataset. The `score_value_1` field should contain numerical values representing hardness scores. However, sometimes data can be messy, and we might encounter values that are not in the expected format (e.g., lists instead of single numbers).\n",
    "\n",
    "The code below demonstrates how to identify rows where `score_value_1` is incorrectly formatted as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f073fdd-f625-490b-829e-1f4a97449456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: score_value_1, dtype: object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_and_hardness[\"score_value_1\"][\n",
    "    topic_and_hardness[\"score_value_1\"].apply(lambda x: isinstance(x, list))\n",
    "].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1779a36b-9613-4223-b480-c9af74bac103",
   "metadata": {},
   "source": [
    "Why do you think `score_value_1` contains lists instead of single values? What might have caused this? What steps would you take to fix this issue so that `score_value_1` contains only numeric values? Are there any other columns that might have similar issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed014e7-fa5f-4b8e-8720-a4453cc7158a",
   "metadata": {},
   "source": [
    "Once you clean the dataset, you can start your analysis by think about the following questions:\n",
    "- Do models perform differently based on hardness scores?\n",
    "- What are the most common topics in the dataset?\n",
    "- Which topics tend to have higher hardness scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc3be19-44db-4816-b8eb-96e26eb176fc",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "You've now explored various aspects of the dataset, including prompt lengths, response lengths, and embeddings, as well as handling messy data. As you proceed, it's important to remember the key **EDA requirements** for this milestone:\n",
    "\n",
    "1. **Ranking of the model based on their win rate or ELO ratings**\n",
    "2. **Distribution of the prompt and response length** \n",
    "4. **Hardness score distribution and its correlation with the models** \n",
    "5. **Open-ended: Visualize the \"variance\" in model performance**\n",
    "6. **Open-ended: Explore the prompt topics in the dataset (topic modeling)**\n",
    "\n",
    "### What Have You Discovered?\n",
    "\n",
    "Now that you've completed the initial exploration through this notebook, think about the following:\n",
    "\n",
    "- **Which insights surprised you?**  \n",
    "- **What further questions would you ask based on the patterns you've seen?**  \n",
    "- **Which analyses are still missing or could be extended?**\n",
    "\n",
    "This notebook provides a foundation for your EDA, but the real insights will come from the questions you ask and the deeper analyses you conduct. Use this notebook as a starting point to explore relationships in the data that will help inform your understanding of chatbot performance. By formulating and answering your questions as a team, you'll gain a richer understanding of the dataset and get ready for the modeling tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
